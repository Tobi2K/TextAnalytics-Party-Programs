@article{zirn2014multidimensional,
  title={Multidimensional topic analysis in political texts},
  author={Zirn, C{\"a}cilia and Stuckenschmidt, Heiner},
  journal={Data \& Knowledge Engineering},
  volume={90},
  pages={38--53},
  year={2014},
  publisher={Elsevier}
}
@inproceedings{stuckenschmidt2012multi,
  title={Multi-dimensional analysis of political documents},
  author={Stuckenschmidt, Heiner and Zirn, C{\"a}cilia},
  booktitle={International Conference on Application of Natural Language to Information Systems},
  pages={11--22},
  year={2012},
  organization={Springer}
}
@article{koh2021predicting,
  title={Predicting Policy Domains from Party Manifestos with BERT and Convolutional Neural Networks},
  author={Koh, Allison and Boey, Daniel Kai Sheng and B{\'e}chara, Hannah},
  year={2021},
  publisher={SocArXiv}
}
@inproceedings{abercrombie2019policy,
  title={Policy preference detection in parliamentary debate motions},
  author={Abercrombie, Gavin and Nanni, Federico and Batista-Navarro, Riza Theresa and Ponzetto, Simone Paolo},
  booktitle={Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)},
  pages={249--259},
  year={2019}
}

@software{bab2min_2021_4999089,
  author       = {Minchul Lee and
                  Douglas Fenstermacher and
                  Jonathan Schneider},
  title        = {bab2min/tomotopy:},
  month        = sept,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.12.2},
  doi          = {10.5281/zenodo.5467561},
  url          = {https://zenodo.org/record/5467561#.Yf_uWPgxm3A}
}

@software{bert-base-german-cased,
  author       = {{MDZ Digital Library team (dbmdz) at the Bavarian State Library}},
  title        = { huggingface/dbmdz/bert-base-german-uncased },
  url          = { https://huggingface.co/dbmdz/bert-base-german-uncased }
}

@article{newman2009distributed,
  title={Distributed algorithms for topic models.},
  author={Newman, David and Asuncion, Arthur and Smyth, Padhraic and Welling, Max},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={8},
  year={2009}
}

@article{teh2004sharing,
  title={Sharing clusters among related groups: Hierarchical Dirichlet processes},
  author={Teh, Yee and Jordan, Michael and Beal, Matthew and Blei, David},
  journal={Advances in neural information processing systems},
  volume={17},
  year={2004}
}

@article{subeno2018optimisation,
  title={Optimisation towards Latent Dirichlet Allocation: Its Topic Number and Collapsed Gibbs Sampling Inference Process.},
  author={Subeno, Bambang and Kusumaningrum, Retno and others},
  journal={International Journal of Electrical \& Computer Engineering (2088-8708)},
  volume={8},
  number={5},
  year={2018}
}

@article{Devlin2019BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  journal={ArXiv},
  year={2019},
  volume={abs/1810.04805}
}

@misc{DevlinPres,
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  howpublished = {\url{https://nlp.stanford.edu/seminar/details/jdevlin.pdf#page=9}},
  note = {Accessed: 2022-02-08}
}

@article{teh2006hierarchical,
  title={Hierarchical dirichlet processes},
  author={Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
  journal={Journal of the american statistical association},
  volume={101},
  number={476},
  pages={1566--1581},
  year={2006},
  publisher={Taylor \& Francis}
}

@INPROCEEDINGS{LDANews,  author={Kusumaningrum, Retno and Wiedjayanto, M. Ihsan Aji and Adhy, Satriyo and Suryono},  booktitle={2016 International Conference on Data and Software Engineering (ICoDSE)},   title={Classification of Indonesian news articles based on Latent Dirichlet Allocation},   year={2016},  volume={},  number={},  pages={1-5},  doi={10.1109/ICODSE.2016.7936106}}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@inproceedings{rehurek_lrec,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@inproceedings{mimno2011optimizing,
  title={Optimizing semantic coherence in topic models},
  author={Mimno, David and Wallach, Hanna and Talley, Edmund and Leenders, Miriam and McCallum, Andrew},
  booktitle={Proceedings of the 2011 conference on empirical methods in natural language processing},
  pages={262--272},
  year={2011}
}

@inbook{Meng2020,
author = {Meng, Yu and Huang, Jiaxin and Wang, Guangyuan and Wang, Zihan and Zhang, Chao and Zhang, Yu and Han, Jiawei},
title = {Discriminative Topic Mining via Category-Name Guided Text Embedding},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380278},
abstract = {Mining a set of meaningful and distinctive topics automatically from massive text corpora has broad applications. Existing topic models, however, typically work in a purely unsupervised way, which often generate topics that do not fit users’ particular needs and yield suboptimal performance on downstream tasks. We propose a new task, discriminative topic mining, which leverages a set of user-provided category names to mine discriminative topics from text corpora. This new task not only helps a user understand clearly and distinctively the topics he/she is most interested in, but also benefits directly keyword-driven classification tasks. We develop CatE, a novel category-name guided text embedding method for discriminative topic mining, which effectively leverages minimal user guidance to learn a discriminative embedding space and discover category representative terms in an iterative manner. We conduct a comprehensive set of experiments to show that CatE mines high-quality set of topics guided by category names only, and benefits a variety of downstream applications including weakly-supervised classification and lexical entailment direction identification.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2121–2132},
numpages = {12}
}

@misc{1706.03762,
Author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
Title = {Attention Is All You Need},
Year = {2017},
Eprint = {arXiv:1706.03762},
}

@inproceedings{zhang2015estimating,
  title={Estimating the uncertainty of average F1 scores},
  author={Zhang, Dell and Wang, Jun and Zhao, Xiaoxue},
  booktitle={Proceedings of the 2015 International conference on the theory of information retrieval},
  pages={317--320},
  year={2015}
}

@INPROCEEDINGS{6033626,

  author={Doumit, Sarjoun and Minai, Ali},

  booktitle={The 2011 International Joint Conference on Neural Networks}, 

  title={Semantic knowledge inference from online news media using an LDA-NLP approach}, 

  year={2011},

  volume={},

  number={},

  pages={3068-3071},

  doi={10.1109/IJCNN.2011.6033626}}

@article{toledo2020multilingual,
  title={Multilingual argument mining: Datasets and analysis},
  author={Toledo-Ronen, Orith and Orbach, Matan and Bilu, Yonatan and Spector, Artem and Slonim, Noam},
  journal={arXiv preprint arXiv:2010.06432},
  year={2020}
}

@INPROCEEDINGS{9666618,

  author={Heidari, Maryam and Zad, Samira and Hajibabaee, Parisa and Malekzadeh, Masoud and HekmatiAthar, SeyyedPooya and Uzuner, Ozlem and Jones, James H},

  booktitle={2021 IEEE 12th Annual Ubiquitous Computing, Electronics   Mobile Communication Conference (UEMCON)}, 

  title={BERT Model for Fake News Detection Based on Social Bot Activities in the COVID-19 Pandemic}, 

  year={2021},

  volume={},

  number={},

  pages={0103-0109},

  doi={10.1109/UEMCON53757.2021.9666618}}


@article{gan2021selection,
  title={Selection of the Optimal Number of Topics for LDA Topic Model—Taking Patent Policy Analysis as an Example},
  author={Gan, Jingxian and Qi, Yong},
  journal={Entropy},
  volume={23},
  number={10},
  pages={1301},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}