{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "class Party(Enum):\n",
    "    AFD = 0\n",
    "    CDU = 1\n",
    "    FDP = 2\n",
    "    GRUENE = 3\n",
    "    LINKE = 4\n",
    "    SPD = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "\n",
    "# stopwords\n",
    "nltk_stopwords = stopwords.words('german')\n",
    "\n",
    "# build stopwords list\n",
    "all_stopwords = list(set(STOP_WORDS) | set(nltk_stopwords))\n",
    "with open('custom_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    all_stopwords += [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load files\n",
    "party_text = {}\n",
    "for party in Party:\n",
    "    all_stopwords.extend(['{}'.format(party.name.lower())])\n",
    "    with open('resources/' + party.name + '.txt', encoding='utf-8', errors='ignore') as txt:\n",
    "        file = \" \".join(l for l in txt)\n",
    "        # remove gender *\n",
    "        file = re.sub(r'\\*innen(\\w*)\\s', r'\\1 ', file)\n",
    "    party_text[party] = file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "topic_clusters = {}\n",
    "\n",
    "topic_clusters[\"JUGEND_UND_FAMILIE\"] = [\"Kinder\", \"Jugend\", \"Familie\", \"Senioren\", \"Eltern\", \"Erziehung\"]\n",
    "topic_clusters[\"BILDUNG\"] = [\"Schule\", \"Gymnasium\", \"Realschule\", \"Grundschule\", \"Mittelschule\", \"Lehrer\", \"Universität\", \"Lehre\", \"Gesamtschule\", \"Bildung\"]\n",
    "topic_clusters[\"SPORT_UND_FREIZEIT\"] = [\"Sport\", \"Freizeit\", \"Aktivität\", \"Fitness\"]\n",
    "topic_clusters[\"WIRTSCHAFT\"] = [\"Wirtschaft\", \"Ökonomie\", \"Geld\", \"Inflation\", \"Preis\", \"Währung\", \"Aktien\", \"Fonds\", \"Börse\", \"Unternehmen\", \"Gehalt\", \"Kredit\"]\n",
    "topic_clusters[\"GESUNDHEIT\"] = [\"Gesundheit\", \"Krankenhaus\", \"Arzt\", \"Doktor\", \"Medizin\", \"Versorgung\", \"Corona\", \"Pflege\", \"Intensiv\", \"\"]\n",
    "topic_clusters[\"ARBEIT_UND_SOZIALES\"] = [\"Arbeit\", \"Gehalt\", \"Arbeitsstelle\", \"Arbeitgeber\", \"Arbeitnehmen\"]\n",
    "topic_clusters[\"INNERE_SICHERHEIT_UND_DATENSCHUTZ\"] = [\"Datenschutz\"]\n",
    "topic_clusters[\"ZUWANDERUNG_UND_INTEGRATION\"] = [\"Diversität\", \"Flüchtlinge\", \"Asyl\", \"Migrant\", \"Immigrant\", \"Toleranz\", \"Zuwanderung\", \"Integration\"]\n",
    "#topic_clusters[\"AUSSENPOLITIK\"] = []\n",
    "topic_clusters[\"UMWELT\"] = [\"Umwelt\", \"Klima\", \"Klimaschutz\", \"Ökologie\", \"CO2\", \"Landwirtschaft\", \"Klimakrise\", \"Treibhaus\", \"Emissionen\"]\n",
    "topic_clusters[\"VERKEHR\"] = [\"Auto\", \"Straße\", \"Flug\", \"Schiff\", \"Reise\", \"Verkehr\", \"Stau\", \"Autobahn\", \"Landstraße\", \"Bundesstraße\"]\n",
    "topic_clusters[\"ENERGIE\"] = [\"Strom\", \"Solar\", \"Windkraft\", \"Wasserkraft\", \"Kohlekraft\", \"Atomkraft\", \"Kernenergie\", \"Energiewende\", \"erneuerbar\", \"Öl\", \"Gas\"]\n",
    "#topic_clusters[\"VERBRAUCHERSCHUTZ\"] = [\"\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-base-german-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-german-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-german-uncased\")\n",
    "model = TFBertModel.from_pretrained(\"dbmdz/bert-base-german-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def convert_to_embeddings(cluster):\n",
    "    idx = tokenizer.encode(cluster)\n",
    "    idx = np.array(idx)[None,:]\n",
    "    embedding = model(idx)\n",
    "    tensor = np.array(embedding[0][0][1:-1])\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def split_in_512_chunks(text):\n",
    "    chunks = []\n",
    "    tokens = text.split(' ')\n",
    "    for i in range(0, len(tokens), 256):\n",
    "        chunks.append(\" \".join(tokens[i: min(i+255, len(tokens) - 1)]))\n",
    "    return chunks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "mean_vectors = [convert_to_embeddings(txt).mean(0) for txt in split_in_512_chunks(party_text[Party.FDP])[:3]]\n",
    "\n",
    "feature_matrix = np.array(mean_vectors)\n",
    "\n",
    "topic_cluster_embeddings = { t: convert_to_embeddings(w) for t, w in topic_clusters.items() }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32906326 0.32893802 0.34199872]\n",
      " [0.34191655 0.33127416 0.3268093 ]\n",
      " [0.33173463 0.32768345 0.34058191]\n",
      " [0.34235638 0.33067732 0.32696629]\n",
      " [0.34196647 0.33004942 0.32798411]\n",
      " [0.32981197 0.32843035 0.34175768]\n",
      " [0.34397971 0.33197895 0.32404134]\n",
      " [0.32801349 0.32972886 0.34225765]\n",
      " [0.32744162 0.32993859 0.34261979]\n",
      " [0.34191655 0.33127416 0.3268093 ]\n",
      " [0.34278387 0.33027306 0.32694306]]\n"
     ]
    }
   ],
   "source": [
    "similarities = np.array([metrics.pairwise.cosine_similarity(feature_matrix, y).T.tolist()[0]\n",
    "                         for y in topic_cluster_embeddings.values()])\n",
    "\n",
    "topics = list(topic_cluster_embeddings.keys())\n",
    "for i in range(len(similarities)):\n",
    "    if sum(similarities[i]) == 0:\n",
    "       similarities[i] = [0]*len(topics)\n",
    "       similarities[i][np.random.choice(range(len(topics)))] = 1\n",
    "    similarities[i] = similarities[i] / sum(similarities[i])\n",
    "\n",
    "predicted_prob = similarities\n",
    "predicted = [topics[np.argmax(pred)] for pred in predicted_prob]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_11447/2498957844.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m## Accuracy, Precision, Recall\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0maccuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtopics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredicted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m auc = metrics.roc_auc_score(topics, predicted_prob,\n\u001B[0m\u001B[1;32m      6\u001B[0m                             multi_class=\"ovr\")\n\u001B[1;32m      7\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Accuracy:\"\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\u001B[0m in \u001B[0;36mroc_auc_score\u001B[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[1;32m    559\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmulti_class\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"raise\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m         return _multiclass_roc_auc_score(\n\u001B[0m\u001B[1;32m    562\u001B[0m             \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_score\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_class\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maverage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m         )\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\u001B[0m in \u001B[0;36m_multiclass_roc_auc_score\u001B[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001B[0m\n\u001B[1;32m    663\u001B[0m         \u001B[0mclasses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    664\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclasses\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0my_score\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 665\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m    666\u001B[0m                 \u001B[0;34m\"Number of classes in y_true not equal to the number of \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    667\u001B[0m                 \u001B[0;34m\"columns in 'y_score'\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "classes = np.unique(topics)\n",
    "y_test_array = pandas.get_dummies(topics, drop_first=False).values\n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(topics, predicted)\n",
    "auc = metrics.roc_auc_score(topics, predicted_prob,\n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(topics, predicted))\n",
    "    ## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(topics, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues,\n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes,\n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],\n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3,\n",
    "              label='{0} (area={1:0.2f})'.format(classes[i],\n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05],\n",
    "          xlabel='False Positive Rate',\n",
    "          ylabel=\"True Positive Rate (Recall)\",\n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    ## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3,\n",
    "               label='{0} (area={1:0.2f})'.format(classes[i],\n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall',\n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}